=================================
Online Safety Act Risk Assessment
=================================

Service name:
	phpc.social

Service type:
	User-to-user (U2U) service

Status:
	Draft

Completion date:
	2025-02-12

Next review/update date:
	2026-04-01

Reason for review:
	Regular review

Completed by:
	Derick Rethans

Named person responsible for the risk assessment:
	XXX

Approved by (governance and accountability channels):
	XXX


.. contents::


Scope Check
===========

1. Does your online service have links with the UK?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Yes

2. Do you provide a “user-to-user” service?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Yes

3. Do you provide a search service?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Yes (you can search content on other mastodon instances)

4. Does your online service publish or display provider pornographic content?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

No, we don’t publish/display any pornographic content

5. Do any exemptions apply to the user-generated content on your online service? Select all that apply
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- [ ] Yes, users can only communicate by email, SMS, MMS and/or one-to-one live aural communications; or
- [ ] Yes, users can only interact with content generated by my business
- [X] No, my service is not limited to these types of content

6. Do any exemptions apply to your online service? Select all that apply
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- [ ] Yes, it is an internal business service, including services such as business intranet, content management systems, or customer relationship management systems
- [ ] Yes, it is provided by a public body, such as Parliament, a UK public authority, or foreign government
- [ ] Yes, it is provided by an UK education or childcare provider
- [X] No, none of the above applies

Step 1: U2U and Search Risk Profiles and Risk Factors
=====================================================

User-to-User Service Risk Profile and Risk Factors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

1. Is your service any of these types?
--------------------------------------

- [X] Social media service
- [X] Messaging service
- [ ] Gaming service
- [ ] Adult service
- [X] Discussion forum or chat room
- [ ] Marketplace or listing service
- [ ] File-sharing or file storage service
- [ ] None of the above

2. Do child users access some or all of the service?
----------------------------------------------------

Yes. We do not actually have this information, so we have to presume that
children might access the service.

3. Does your service include any of these user identification functionalities?
------------------------------------------------------------------------------

- [X] User profiles
- [ ] Anonymous user profiles or users without accounts
- [ ] None of the above

*Note:* Posted content is available for users without accounts, but there is
no way to identify these users.

4. Does your service include any of these user networking functionalities?
--------------------------------------------------------------------------

- [X] Users can connect with other users
- [X] Users can form closed groups or send group messages
- [ ] None of the above

5. Does your service include any of these user communication functionalities?
-----------------------------------------------------------------------------

- [ ] Livestreaming (either open or closed channels)
- [X] Direct messaging (including ephemeral direct messaging)
- [ ] Encrypted messaging
- [X] Commenting on content
- [X] Posting or sending images or videos (either open or closed channels)
- [ ] Posting or sending location information
- [X] Re-posting or forwarding content
- [ ] None of the above

Users could post their own location, but this is not a feature that the
service provides directly.

6. Does your service allow users to post goods and services for sale?
---------------------------------------------------------------------

No.

*Note:* We have policies in place to limit what users may post regarding
advertisement. As so far, nobody has posted anything directly for sale yet.

7. Does your service include any of the following functionalities that allow users to find or encounter content? Tick all that apply.
-------------------------------------------------------------------------------------------------------------------------------------

- [X] Searching for user-generated content
- [X] Hyperlinking
- [ ] None of the above

8. Does your service use content or network recommender systems?
----------------------------------------------------------------

No

Search Service Risk Profile and Risk Factors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

1. Is your service any of the following service types?
------------------------------------------------------

Vertical search services

2. Do child users access your service?
--------------------------------------

Yes

3. Does your service have any of the following functionalities? 
----------------------------------------------------------------

Tick all that apply.

- [X] Provide users with search predictions or suggestions
- [X] Allow users to search for photographs, videos or visual images


Step 2: U2U and Search: Assess the risk of harm
===============================================

Additional characteristics and existing controls
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Some definitions:

Absence of Harmful Content
	Since our start of operations in 2018, there have been 859 reports by our
	users. None of these reports were about harmful content posted by any of
	our users. We also did not have to remove any content posted by our users.

Active Moderation Team
	Our moderation team is 18 strong, and separated over a diverse group of
	countries spanning 9 time zones. Most valid user generated reports are
	dealt with within a few minutes. Our moderation team also follows user
	posted content as far as possible. No harmful content was identified that
	way either.

Code of Conduct
	We have a long standing Code of Conduct (https://phpc.social/about).

No Child Users
	We have no evidence of children posting or visiting our service in any
	significant numbers. Our Privacy Policy also explicitly say that the
	service might not be used for people under the age of 18.

Reporting Features
	Our software uses industry standard reporting functions which are easily
	accessible from within the service, as well as through third party
	clients. We also provide a direct email address in addition to the
	in-service feature on our Code of Conduct page.

Risk levels and evidence
~~~~~~~~~~~~~~~~~~~~~~~~

Terrorism
---------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*


Child sexual exploitation and abuse (CSEA) offences
---------------------------------------------------

Risk level:
	Low [#crisk]_

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *No Child Users*

Grooming (child sexual exploitation and abuse)
----------------------------------------------

Risk level:
	Low [#crisk]_

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *No Child Users*

Image-based child sexual abuse material
---------------------------------------

Risk level:
	Low [#crisk]_

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *No Child Users*

Child sexual abuse material URLs
--------------------------------

Risk level:
	Low [#crisk]_

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *No Child Users*

Hate
----

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Harassment, stalking, threats and abuse offences
------------------------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *Reporting Features*

Controlling or coercive behaviour
---------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*, *Reporting Features*

Intimate image abuse
--------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Extreme pornography offence
---------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Sexual exploitation of adults
-----------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Human trafficking
-----------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Unlawful immigration
--------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Fraud and financial services offences
-------------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Proceeds of crime
-----------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Drugs and psychoactive substances
---------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Firearms, knives and other weapons
----------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Encouraging or assisting suicide (or attempted suicide)
-------------------------------------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Foreign interference offence
----------------------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	None

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

Animal cruelty
--------------

Risk level:
	Negligible

Risk factors considered:
	Unlikely on our small topic-specific Mastodon/Fediverse instance with an
	*Active Moderation Team*.
	
Additional characteristics considered:
	Although the Elephpant is our mascot, no elephants were harmed in the
	creation of it, nor its toy cousins.

Existing controls considered:
	*Active Moderation Team*, *Reporting Features*

Evidence:
	*Absence of Harmful Content*

.. [#crisk] Those risk levels above that are assessed as "Low" are considered
   "Negligible" but the Ofcom guidance suggests that these can only be
   assessed as "Negligible" in very specific circumstances that don't apply
   here.

Step 3: U2U and Search: Decide measures, implement and record
=============================================================

How many monthly active UK users does your service have?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Our instance has 878 active users in the last 30 days, which include non-UK users.

With 1.21TB of bandwidth total, and 84GB i(7%) was served via London PoP, we
estimate 100 (12%) UK users.


ICU A2: Individual accountable for illegal content safety duties and reporting and complaints duties
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Pending

Date measure takes/took effect
	?

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(2), (3), and (5) to (9). Section 20(2). Section 21(2) and (3) Online Safety Act 2023



ICU C1: Content moderation function to review and assess suspected illegal content
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2022-04-25

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(2) and(3). Section 21(2)(b) Online Safety Act 2023


ICU C2: Having a content moderation function that allows for the swift take down of illegal content
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2022-04-25

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(2) and (3). Section 21(2)(b) Online Safety Act 2023


ICU D1: Enabling complaints
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 20(2). Section 21(2)(a) Online Safety Act 2023

ICU D2: Having easy to find, easy to access and easy to use complaints systems and processes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 20(2). Section 21(2)(c) Online Safety Act 2023


ICS D6: Appropriate action: Complaints about suspected illegal content
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 27(3). Section 32(2)(b) Online Safety Act 2023


ICU D7: Appropriate action for relevant complaints about suspected illegal content
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(3). Section 21(2)(b) Online Safety Act 2023


ICU D8: Appropriate action for relevant complaints which are appeals – determination (services that are neither large general nor multi-risk)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2022-04-25

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 32(2)(b) Online Safety Act 2023


ICU D9: Appropriate action for relevant complaints which are appeals – determination
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2022-04-25

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 21(2)(B) Online Safety Act 2023

ICU D10: Appropriate action for relevant complaints which are appeals – action following determination
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2022-04-25

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 21(2)(b) Online Safety Act 2023

ICU D11: Appropriate action for relevant complaints about proactive technology, which are not appeals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Not Implemented

Date measure takes/took effect
	N/A, we do not use proactive *technology*, but we do proactively look at
	posted content.

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 21(2)(b) Online Safety Act 2023

ICU D12: Appropriate action for all other relevant complaints
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 21(2)(b) Online Safety Act 2023

ICU D13: Exception: manifestly unfounded complaints
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 21(2)(b) Online Safety Act 2023


ICU G1: Terms of service: substance (all services)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2025-02-14

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(5) and (7). Section 21(3) Online Safety Act 2023


ICU G3: Terms of service: clarity and accessibility
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Child sexual exploitation and abuse, Terrorism, Other duties

Relevant duties
	Section 10(8). Section 21(3) Online Safety Act 2023


ICU H1: Removing accounts of proscribed organisations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Status
	Implemented

Date measure takes/took effect
	2018-08-13

Relevant codes
	Terrorism

Relevant duties
	Section 10(2) and 10(3) Online Safety Act 2023


Step 4: U2U and Search: Report, review, and update risk assessments
===================================================================

Date of next annual risk assessment: April 1st

Confirmation findings of the illegal content risk assessment have been reported, and recorded: Yes, here.

Date the findings of the illegal content risk assessment were reported, and
recorded: 2025-02-12

Information on how you take appropriate steps to keep the risk assessment up
to date (for example, a written policy): Review should any content be posted
that might change the above risk assessment. Annual review on 1 April each
year.

Children's Access Assessment
============================

[See: https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/quick-guide-to-childrens-access-assessments/]

Stage 1
~~~~~~~

Is it possible for children to access the service or part of it?
	Yes

*Note:* the instance is public, and "accessing the service" includes visiting
the site without logging in or posting. We don't have any age verification
tools, or limits on the ages of people viewing the forum.

Stage 2
~~~~~~~

Are there a significant number of children who are users of the service?
	No

*Note:* We have no evidence of children accessing our service. It is
impossible to know whether visitors are aged under 18 or not, all we have is
an IP address.

Is the service of a kind likely to attract a significant number of children?
	No

*Note:* Topic of our Mastodon instance is the PHP computer
language, which children could potentially be interested in. However, there
has not been any evidence of content specifically made for children.

Result
	No need to carry out a Children's Risk Assessment.
